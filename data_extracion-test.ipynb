{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli chcesz mieć dużo i legalnie, to zamiast gazet z paywallem warto dodać:\n",
    "Bankier.pl – darmowe, często cytują ekonomistów („NBP przewiduje inflację 3,8% w 2025 r.”).\n",
    " Teksty łatwe do scrapowania.\n",
    "\n",
    "\n",
    "Money.pl – często piszą: „Według analityków X prognoza wzrostu PKB wyniesie 2,7%...”.\n",
    "\n",
    "\n",
    "Business Insider Polska – ma wiele otwartych artykułów, szczególnie sekcja „Gospodarka”.\n",
    "\n",
    "\n",
    "Forsal.pl / Dziennik Gazeta Prawna – część tekstów otwarta, można brać akapity.\n",
    "\n",
    "\n",
    "Interia Biznes, Wirtualna Polska Gospodarka – popularne serwisy z cytatami ekonomistów.\n",
    "\n",
    "\n",
    "PAP Biznes (biznes.pap.pl) – krótkie notki agencyjne z konkretnymi liczbami, idealne do ekstrakcji.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, date\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (compatible; MagisterkaBot/0.1; +https://example.com/contact)\"\n",
    "}\n",
    "\n",
    "\n",
    "def fetch_html(url: str, sleep: float = 1.0) -> str:\n",
    "    \"\"\"Pobiera HTML z podanego URL z prostym backoffem.\"\"\"\n",
    "    resp = requests.get(url, headers=HEADERS, timeout=15)\n",
    "    resp.raise_for_status()\n",
    "    time.sleep(sleep)\n",
    "    return resp.text\n",
    "\n",
    "\n",
    "def parse_date(raw: str) -> date | None:\n",
    "    \"\"\"Próbuje sparsować datę z różnych formatów spotykanych w PL mediach.\"\"\"\n",
    "    if not raw:\n",
    "        return None\n",
    "    raw = raw.strip()\n",
    "\n",
    "    fmts = [\n",
    "        \"%Y-%m-%d\",\n",
    "        \"%Y-%m-%d %H:%M\",\n",
    "        \"%Y-%m-%d %H:%M:%S\",\n",
    "        \"%d.%m.%Y\",\n",
    "        \"%d.%m.%Y %H:%M\",\n",
    "        \"%d-%m-%Y\",\n",
    "        \"%d %m %Y\",\n",
    "        \"%d %b %Y\",\n",
    "        \"%d %B %Y\",\n",
    "    ]\n",
    "    for fmt in fmts:\n",
    "        try:\n",
    "            return datetime.strptime(raw, fmt).date()\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    m = re.search(r\"\\b(\\d{4})-(\\d{2})-(\\d{2})\\b\", raw)\n",
    "    if m:\n",
    "        y, mth, d = map(int, m.groups())\n",
    "        return date(y, mth, d)\n",
    "\n",
    "    m = re.search(r\"\\b(\\d{1,2})[./-](\\d{1,2})[./-](\\d{4})\\b\", raw)\n",
    "    if m:\n",
    "        d, mth, y = map(int, m.groups())\n",
    "        try:\n",
    "            return date(y, mth, d)\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def search_date_in_text(text: str) -> date | None:\n",
    "    \"\"\"Szukamy pierwszego wystąpienia daty w tekście.\"\"\"\n",
    "    m = re.search(r\"\\b(20[12]\\d)-(0[1-9]|1[0-2])-(0[1-9]|[12]\\d|3[01])\\b\", text)\n",
    "    if m:\n",
    "        y, mth, d = map(int, m.groups())\n",
    "        return date(y, mth, d)\n",
    "\n",
    "    m = re.search(r\"\\b(0?[1-9]|[12]\\ \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "SESSION = requests.Session()\n",
    "SESSION.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0 Safari/537.36\"\n",
    "})\n",
    "\n",
    "DATE_PATTERNS = [\n",
    "    re.compile(r\"\\b\\d{4}-\\d{2}-\\d{2}(?:[ T]\\d{2}:\\d{2}(?::\\d{2})?)?\\b\"),  # 2023-09-01 12:34\n",
    "    re.compile(r\"\\b\\d{1,2}[./-]\\d{1,2}[./-]\\d{4}(?:[ ,T]+\\d{2}:\\d{2}(?::\\d{2})?)?\\b\")  # 01.09.2023, 12:34\n",
    "]\n",
    "\n",
    "def _is_bankier(url: str) -> bool:\n",
    "    host = urlparse(url).netloc.lower()\n",
    "    return \"bankier.pl\" in host\n",
    "\n",
    "def _find_date_in_text(text: str) -> str | None:\n",
    "    if not text:\n",
    "        return None\n",
    "    t = \" \".join(text.split())\n",
    "    for rx in DATE_PATTERNS:\n",
    "        m = rx.search(t)\n",
    "        if m:\n",
    "            return m.group(0)\n",
    "    return None\n",
    "\n",
    "def _extract_bankier_date(soup: BeautifulSoup) -> str | None:\n",
    "    # Search in class a-span\n",
    "    for el in soup.select(\"span.a-span\"):\n",
    "        txt = el.get_text(strip=True)\n",
    "        d = _find_date_in_text(txt) or txt\n",
    "        if d:\n",
    "            # Return the first valid date\n",
    "            return d\n",
    "    return None\n",
    "\n",
    "def _extract_meta_date(soup: BeautifulSoup) -> str | None:\n",
    "    # Simple fallback with meta/time\n",
    "    meta_candidates = [\n",
    "        (\"meta\", {\"property\": \"article:published_time\"}, \"content\"),\n",
    "        (\"meta\", {\"name\": \"article:published_time\"}, \"content\"),\n",
    "        (\"meta\", {\"itemprop\": \"datePublished\"}, \"content\"),\n",
    "        (\"meta\", {\"name\": \"date\"}, \"content\"),\n",
    "    ]\n",
    "    for tag, attrs, attr_name in meta_candidates:\n",
    "        el = soup.find(tag, attrs=attrs)\n",
    "        if el and el.has_attr(attr_name):\n",
    "            d = _find_date_in_text(el.get(attr_name, \"\")) or el.get(attr_name, \"\")\n",
    "            if d:\n",
    "                return d\n",
    "    time_el = soup.find(\"time\")\n",
    "    if time_el:\n",
    "        if time_el.has_attr(\"datetime\"):\n",
    "            d = _find_date_in_text(time_el[\"datetime\"]) or time_el[\"datetime\"]\n",
    "            if d:\n",
    "                return d\n",
    "        txt = time_el.get_text(strip=True)\n",
    "        d = _find_date_in_text(txt) or txt\n",
    "        if d:\n",
    "            return d\n",
    "    return None\n",
    "\n",
    "def _extract_title(soup: BeautifulSoup) -> str | None:\n",
    "    og = soup.find(\"meta\", property=\"og:title\")\n",
    "    if og and og.get(\"content\"):\n",
    "        return og[\"content\"].strip()\n",
    "    h1 = soup.find(\"h1\")\n",
    "    if h1:\n",
    "        return h1.get_text(strip=True)\n",
    "    if soup.title and soup.title.string:\n",
    "        return soup.title.string.strip()\n",
    "    return None\n",
    "\n",
    "def _extract_text(soup: BeautifulSoup) -> str:\n",
    "    # Collect paragraphs from <article>, then globally\n",
    "    parts = []\n",
    "    article = soup.find(\"article\")\n",
    "    if article:\n",
    "        parts = [p.get_text(\" \", strip=True) for p in article.find_all(\"p\")]\n",
    "    if not parts:\n",
    "        parts = [p.get_text(\" \", strip=True) for p in soup.find_all(\"p\")]\n",
    "    return \"\\n\\n\".join([t for t in parts if t])\n",
    "\n",
    "def extract_generic_article(url: str) -> dict:\n",
    "    resp = SESSION.get(url, timeout=20)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    title = _extract_title(soup)\n",
    "    if _is_bankier(url):\n",
    "        date = _extract_bankier_date(soup)\n",
    "    else:\n",
    "        date = _extract_meta_date(soup)\n",
    "\n",
    "    text = _extract_text(soup)\n",
    "    return {\"title\": title, \"date\": date, \"text\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TYTUŁ =====\n",
      "Kuczyński: Recesja w 2023 roku to \"pewniak\" ekonomistów. Polska może mieć jednak szczęście\n",
      "\n",
      "===== DATA =====\n",
      "2022-12-31 06:35\n",
      "\n",
      "===== FRAGMENT TEKSTU =====\n",
      "Polska gospodarka trzyma się zaskakująco dobrze. Dane za listopad okazały się w większości lepsze od prognozowanych przez ekonomistów, mimo wysokiej na tle innych krajów inflacji, i większość przewidywań na 2023 rok nie zakłada spadku PKB. Średnio mowa jest o wzroście o 0,5 proc., choć są i wskazania nawet trzykrotnie bardziej optymistyczne. Wiele zależeć będzie od kursu eurodolara i sytuacji w gospodarce niemieckiej, która z kolei nakierowana jest na eksport do Chin.\n",
      "\n",
      "− Scenariusze na 2023 rok są właściwie dwa: albo recesja, ale wtedy płytka i stosunkowo krótka, np. 1-2 kwartały, albo brak recesji i bardzo wolny wzrost gospodarczy. Rząd zakłada, że będzie to wolny wzrost gospodarczy - o 1,7 proc. PKB . To jest bardzo maleńko, ale wiele innych instytucji finansowych mówi o niewielkim spadku, więc fifty-fifty - mówi agencji informacyjnej Newseria Biznes Piotr Kuczyński, analityk Domu Inwestycyjnego Xelion.\n",
      "\n",
      "W przyszłym roku zdecydowana większość instytucji finansowych czy organizacji mi\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    url = \"https://www.bankier.pl/wiadomosc/Kuczynski-Recesja-w-2023-roku-to-pewniak-ekonomistow-Polska-moze-miec-jednak-szczescie-8463778.html\"\n",
    "    \n",
    "    article = extract_generic_article(url)\n",
    "    \n",
    "    print(\"\\n===== TYTUŁ =====\")\n",
    "    print(article[\"title\"])\n",
    "    \n",
    "    print(\"\\n===== DATA =====\")\n",
    "    print(article[\"date\"])\n",
    "    \n",
    "    print(\"\\n===== FRAGMENT TEKSTU =====\")\n",
    "    print(article[\"text\"][:1000])  # pokaż tylko pierwsze 1000 znaków, żeby nie zalało konsoli\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
