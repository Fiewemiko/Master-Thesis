{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] üîç Sprawdzanie po≈ÇƒÖczenia z Google Custom Search API...\n",
      "[INFO] ‚úÖ Po≈ÇƒÖczenie z API dzia≈Ça poprawnie.\n",
      "\n",
      "[INFO] üìä Rozpoczynam scrapowanie dla 6 stron i 3 lat...\n",
      "[INFO] ‚ö†Ô∏è  Limit Google API: maksymalnie 100 wynik√≥w na zapytanie (10 stron).\n",
      "\n",
      "\n",
      "==================================================\n",
      "[INFO] Przetwarzanie wska≈∫nik√≥w ekonomicznych dla forsal.pl, rok 2021\n",
      "==================================================\n",
      "\n",
      "[INFO] Zapytanie: site:forsal.pl prognoza inflacji 2021\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Brak dalszych wynik√≥w.\n",
      "[INFO] Zebrano 0 nowych rekord√≥w (prognoza inflacji 2021)\n",
      "\n",
      "[INFO] Zapytanie: site:forsal.pl prognoza PKB 2021\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Brak dalszych wynik√≥w.\n",
      "[INFO] Zebrano 0 nowych rekord√≥w (prognoza PKB 2021)\n",
      "\n",
      "[INFO] Zapytanie: site:forsal.pl prognoza wzrostu gospodarczego 2021\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Brak dalszych wynik√≥w.\n",
      "[INFO] Zebrano 0 nowych rekord√≥w (prognoza wzrostu gospodarczego 2021)\n",
      "\n",
      "[INFO] Zapytanie: site:forsal.pl prognoza bezrobocia 2021\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Brak dalszych wynik√≥w.\n",
      "[INFO] Zebrano 0 nowych rekord√≥w (prognoza bezrobocia 2021)\n",
      "\n",
      "[INFO] Zapytanie: site:forsal.pl prognoza stopy referencyjnej NBP 2021\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Brak dalszych wynik√≥w.\n",
      "[INFO] Zebrano 0 nowych rekord√≥w (prognoza stopy referencyjnej NBP 2021)\n",
      "[INFO] Zebrano 0 nowych rekord√≥w dla wszystkich wska≈∫nik√≥w\n",
      "[INFO] Brak nowych rekord√≥w do dodania ‚Üí csv_ze_stron/forsal_pl_2021.csv\n",
      "\n",
      "==================================================\n",
      "[INFO] Przetwarzanie wska≈∫nik√≥w ekonomicznych dla forsal.pl, rok 2022\n",
      "==================================================\n",
      "\n",
      "[INFO] Zapytanie: site:forsal.pl prognoza inflacji 2022\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Brak dalszych wynik√≥w.\n",
      "[INFO] Zebrano 0 nowych rekord√≥w (prognoza inflacji 2022)\n",
      "\n",
      "[INFO] Zapytanie: site:forsal.pl prognoza PKB 2022\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Brak dalszych wynik√≥w.\n",
      "[INFO] Zebrano 0 nowych rekord√≥w (prognoza PKB 2022)\n",
      "\n",
      "[INFO] Zapytanie: site:forsal.pl prognoza wzrostu gospodarczego 2022\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Brak dalszych wynik√≥w.\n",
      "[INFO] Zebrano 0 nowych rekord√≥w (prognoza wzrostu gospodarczego 2022)\n",
      "\n",
      "[INFO] Zapytanie: site:forsal.pl prognoza bezrobocia 2022\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Brak dalszych wynik√≥w.\n",
      "[INFO] Zebrano 0 nowych rekord√≥w (prognoza bezrobocia 2022)\n",
      "\n",
      "[INFO] Zapytanie: site:forsal.pl prognoza stopy referencyjnej NBP 2022\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Brak dalszych wynik√≥w.\n",
      "[INFO] Zebrano 0 nowych rekord√≥w (prognoza stopy referencyjnej NBP 2022)\n",
      "[INFO] Zebrano 0 nowych rekord√≥w dla wszystkich wska≈∫nik√≥w\n",
      "[INFO] Brak nowych rekord√≥w do dodania ‚Üí csv_ze_stron/forsal_pl_2022.csv\n",
      "\n",
      "==================================================\n",
      "[INFO] Przetwarzanie wska≈∫nik√≥w ekonomicznych dla forsal.pl, rok 2023\n",
      "==================================================\n",
      "\n",
      "[INFO] Zapytanie: site:forsal.pl prognoza inflacji 2023\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Brak dalszych wynik√≥w.\n",
      "[INFO] Zebrano 0 nowych rekord√≥w (prognoza inflacji 2023)\n",
      "\n",
      "[INFO] Zapytanie: site:forsal.pl prognoza PKB 2023\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Brak dalszych wynik√≥w.\n",
      "[INFO] Zebrano 0 nowych rekord√≥w (prognoza PKB 2023)\n",
      "\n",
      "[INFO] Zapytanie: site:forsal.pl prognoza wzrostu gospodarczego 2023\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Brak dalszych wynik√≥w.\n",
      "[INFO] Zebrano 0 nowych rekord√≥w (prognoza wzrostu gospodarczego 2023)\n",
      "\n",
      "[INFO] Zapytanie: site:forsal.pl prognoza bezrobocia 2023\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Brak dalszych wynik√≥w.\n",
      "[INFO] Zebrano 0 nowych rekord√≥w (prognoza bezrobocia 2023)\n",
      "\n",
      "[INFO] Zapytanie: site:forsal.pl prognoza stopy referencyjnej NBP 2023\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Brak dalszych wynik√≥w.\n",
      "[INFO] Zebrano 0 nowych rekord√≥w (prognoza stopy referencyjnej NBP 2023)\n",
      "[INFO] Zebrano 0 nowych rekord√≥w dla wszystkich wska≈∫nik√≥w\n",
      "[INFO] Brak nowych rekord√≥w do dodania ‚Üí csv_ze_stron/forsal_pl_2023.csv\n",
      "\n",
      "==================================================\n",
      "[INFO] Przetwarzanie wska≈∫nik√≥w ekonomicznych dla businessinsider.com.pl, rok 2021\n",
      "==================================================\n",
      "\n",
      "[INFO] Zapytanie: site:businessinsider.com.pl prognoza inflacji 2021\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Pobieranie wynik√≥w start=11\n",
      "[INFO]  Pobieranie wynik√≥w start=21\n",
      "[INFO]  Pobieranie wynik√≥w start=31\n",
      "[INFO]  Pobieranie wynik√≥w start=41\n",
      "[INFO]  Pobieranie wynik√≥w start=51\n",
      "[INFO]  Pobieranie wynik√≥w start=61\n",
      "[INFO]  Pobieranie wynik√≥w start=71\n",
      "[INFO]  Pobieranie wynik√≥w start=81\n",
      "[INFO]  Pobieranie wynik√≥w start=91\n",
      "[INFO] Zebrano 100 nowych rekord√≥w (prognoza inflacji 2021)\n",
      "\n",
      "[INFO] Zapytanie: site:businessinsider.com.pl prognoza PKB 2021\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Pobieranie wynik√≥w start=11\n",
      "[INFO]  Pobieranie wynik√≥w start=21\n",
      "[INFO]  Pobieranie wynik√≥w start=31\n",
      "[INFO]  Pobieranie wynik√≥w start=41\n",
      "[INFO]  Pobieranie wynik√≥w start=51\n",
      "[INFO]  Pobieranie wynik√≥w start=61\n",
      "[INFO]  Pobieranie wynik√≥w start=71\n",
      "[INFO]  Pobieranie wynik√≥w start=81\n",
      "[INFO]  Pobieranie wynik√≥w start=91\n",
      "[INFO] Zebrano 99 nowych rekord√≥w (prognoza PKB 2021)\n",
      "\n",
      "[INFO] Zapytanie: site:businessinsider.com.pl prognoza wzrostu gospodarczego 2021\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Pobieranie wynik√≥w start=11\n",
      "[INFO]  Pobieranie wynik√≥w start=21\n",
      "[INFO]  Pobieranie wynik√≥w start=31\n",
      "[INFO]  Pobieranie wynik√≥w start=41\n",
      "[INFO]  Pobieranie wynik√≥w start=51\n",
      "[INFO]  Pobieranie wynik√≥w start=61\n",
      "[INFO]  Pobieranie wynik√≥w start=71\n",
      "[INFO]  Pobieranie wynik√≥w start=81\n",
      "[INFO]  Pobieranie wynik√≥w start=91\n",
      "[INFO] Zebrano 100 nowych rekord√≥w (prognoza wzrostu gospodarczego 2021)\n",
      "\n",
      "[INFO] Zapytanie: site:businessinsider.com.pl prognoza bezrobocia 2021\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Pobieranie wynik√≥w start=11\n",
      "[INFO]  Pobieranie wynik√≥w start=21\n",
      "[INFO]  Pobieranie wynik√≥w start=31\n",
      "[INFO]  Pobieranie wynik√≥w start=41\n",
      "[INFO]  Pobieranie wynik√≥w start=51\n",
      "[INFO]  Pobieranie wynik√≥w start=61\n",
      "[INFO]  Pobieranie wynik√≥w start=71\n",
      "[INFO]  Pobieranie wynik√≥w start=81\n",
      "[INFO]  Pobieranie wynik√≥w start=91\n",
      "[INFO] Zebrano 100 nowych rekord√≥w (prognoza bezrobocia 2021)\n",
      "\n",
      "[INFO] Zapytanie: site:businessinsider.com.pl prognoza stopy referencyjnej NBP 2021\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Pobieranie wynik√≥w start=11\n",
      "[INFO]  Pobieranie wynik√≥w start=21\n",
      "[INFO]  Pobieranie wynik√≥w start=31\n",
      "[INFO]  Pobieranie wynik√≥w start=41\n",
      "[INFO]  Pobieranie wynik√≥w start=51\n",
      "[INFO]  Pobieranie wynik√≥w start=61\n",
      "[INFO]  Pobieranie wynik√≥w start=71\n",
      "[INFO]  Pobieranie wynik√≥w start=81\n",
      "[INFO]  Pobieranie wynik√≥w start=91\n",
      "[INFO] Zebrano 98 nowych rekord√≥w (prognoza stopy referencyjnej NBP 2021)\n",
      "[INFO] Zebrano 497 nowych rekord√≥w dla wszystkich wska≈∫nik√≥w\n",
      "[INFO] Dodano 3 nowych rekord√≥w ‚Üí csv_ze_stron/businessinsider_com_pl_2021.csv\n",
      "\n",
      "==================================================\n",
      "[INFO] Przetwarzanie wska≈∫nik√≥w ekonomicznych dla businessinsider.com.pl, rok 2022\n",
      "==================================================\n",
      "\n",
      "[INFO] Zapytanie: site:businessinsider.com.pl prognoza inflacji 2022\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Pobieranie wynik√≥w start=11\n",
      "[INFO]  Pobieranie wynik√≥w start=21\n",
      "[INFO]  Pobieranie wynik√≥w start=31\n",
      "[INFO]  Pobieranie wynik√≥w start=41\n",
      "[INFO]  Pobieranie wynik√≥w start=51\n",
      "[INFO]  Pobieranie wynik√≥w start=61\n",
      "[INFO]  Pobieranie wynik√≥w start=71\n",
      "[INFO]  Pobieranie wynik√≥w start=81\n",
      "[INFO]  Pobieranie wynik√≥w start=91\n",
      "[INFO] Zebrano 98 nowych rekord√≥w (prognoza inflacji 2022)\n",
      "\n",
      "[INFO] Zapytanie: site:businessinsider.com.pl prognoza PKB 2022\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Pobieranie wynik√≥w start=11\n",
      "[INFO]  Pobieranie wynik√≥w start=21\n",
      "[INFO]  Pobieranie wynik√≥w start=31\n",
      "[INFO]  Pobieranie wynik√≥w start=41\n",
      "[INFO]  Pobieranie wynik√≥w start=51\n",
      "[INFO]  Pobieranie wynik√≥w start=61\n",
      "[INFO]  Pobieranie wynik√≥w start=71\n",
      "[INFO]  Pobieranie wynik√≥w start=81\n",
      "[INFO]  Pobieranie wynik√≥w start=91\n",
      "[INFO] Zebrano 100 nowych rekord√≥w (prognoza PKB 2022)\n",
      "\n",
      "[INFO] Zapytanie: site:businessinsider.com.pl prognoza wzrostu gospodarczego 2022\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Pobieranie wynik√≥w start=11\n",
      "[INFO]  Pobieranie wynik√≥w start=21\n",
      "[INFO]  Pobieranie wynik√≥w start=31\n",
      "[INFO]  Pobieranie wynik√≥w start=41\n",
      "[INFO]  Pobieranie wynik√≥w start=51\n",
      "[INFO]  Pobieranie wynik√≥w start=61\n",
      "[INFO]  Pobieranie wynik√≥w start=71\n",
      "[INFO]  Pobieranie wynik√≥w start=81\n",
      "[INFO]  Pobieranie wynik√≥w start=91\n",
      "[INFO] Zebrano 98 nowych rekord√≥w (prognoza wzrostu gospodarczego 2022)\n",
      "\n",
      "[INFO] Zapytanie: site:businessinsider.com.pl prognoza bezrobocia 2022\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Pobieranie wynik√≥w start=11\n",
      "[INFO]  Pobieranie wynik√≥w start=21\n",
      "[INFO]  Pobieranie wynik√≥w start=31\n",
      "[INFO]  Pobieranie wynik√≥w start=41\n",
      "[INFO]  Pobieranie wynik√≥w start=51\n",
      "[INFO]  Pobieranie wynik√≥w start=61\n",
      "[INFO]  Pobieranie wynik√≥w start=71\n",
      "[INFO]  Pobieranie wynik√≥w start=81\n",
      "[INFO]  Pobieranie wynik√≥w start=91\n",
      "[INFO] Zebrano 100 nowych rekord√≥w (prognoza bezrobocia 2022)\n",
      "\n",
      "[INFO] Zapytanie: site:businessinsider.com.pl prognoza stopy referencyjnej NBP 2022\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Pobieranie wynik√≥w start=11\n",
      "[INFO]  Pobieranie wynik√≥w start=21\n",
      "[INFO]  Pobieranie wynik√≥w start=31\n",
      "[INFO]  Pobieranie wynik√≥w start=41\n",
      "[INFO]  Pobieranie wynik√≥w start=51\n",
      "[INFO]  Pobieranie wynik√≥w start=61\n",
      "[INFO]  Pobieranie wynik√≥w start=71\n",
      "[INFO]  Pobieranie wynik√≥w start=81\n",
      "[INFO]  Pobieranie wynik√≥w start=91\n",
      "[INFO] Zebrano 100 nowych rekord√≥w (prognoza stopy referencyjnej NBP 2022)\n",
      "[INFO] Zebrano 496 nowych rekord√≥w dla wszystkich wska≈∫nik√≥w\n",
      "[INFO] Wszystkie URL-e ju≈º istniejƒÖ ‚Üí csv_ze_stron/businessinsider_com_pl_2022.csv\n",
      "\n",
      "==================================================\n",
      "[INFO] Przetwarzanie wska≈∫nik√≥w ekonomicznych dla businessinsider.com.pl, rok 2023\n",
      "==================================================\n",
      "\n",
      "[INFO] Zapytanie: site:businessinsider.com.pl prognoza inflacji 2023\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Pobieranie wynik√≥w start=11\n",
      "[INFO]  Pobieranie wynik√≥w start=21\n",
      "[INFO]  Pobieranie wynik√≥w start=31\n",
      "[INFO]  Pobieranie wynik√≥w start=41\n",
      "[INFO]  Pobieranie wynik√≥w start=51\n",
      "[INFO]  Pobieranie wynik√≥w start=61\n",
      "[INFO]  Pobieranie wynik√≥w start=71\n",
      "[INFO]  Pobieranie wynik√≥w start=81\n",
      "[INFO]  Pobieranie wynik√≥w start=91\n",
      "[INFO] Zebrano 100 nowych rekord√≥w (prognoza inflacji 2023)\n",
      "\n",
      "[INFO] Zapytanie: site:businessinsider.com.pl prognoza PKB 2023\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Pobieranie wynik√≥w start=11\n",
      "[INFO]  Pobieranie wynik√≥w start=21\n",
      "[INFO]  Pobieranie wynik√≥w start=31\n",
      "[INFO]  Pobieranie wynik√≥w start=41\n",
      "[INFO]  Pobieranie wynik√≥w start=51\n",
      "[INFO]  Pobieranie wynik√≥w start=61\n",
      "[INFO]  Pobieranie wynik√≥w start=71\n",
      "[INFO]  Pobieranie wynik√≥w start=81\n",
      "[INFO]  Pobieranie wynik√≥w start=91\n",
      "[INFO] Zebrano 100 nowych rekord√≥w (prognoza PKB 2023)\n",
      "\n",
      "[INFO] Zapytanie: site:businessinsider.com.pl prognoza wzrostu gospodarczego 2023\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Pobieranie wynik√≥w start=11\n",
      "[INFO]  Pobieranie wynik√≥w start=21\n",
      "[INFO]  Pobieranie wynik√≥w start=31\n",
      "[INFO]  Pobieranie wynik√≥w start=41\n",
      "[INFO]  Pobieranie wynik√≥w start=51\n",
      "[INFO]  Pobieranie wynik√≥w start=61\n",
      "[INFO]  Pobieranie wynik√≥w start=71\n",
      "[INFO]  Pobieranie wynik√≥w start=81\n",
      "[INFO]  Pobieranie wynik√≥w start=91\n",
      "[INFO] Zebrano 99 nowych rekord√≥w (prognoza wzrostu gospodarczego 2023)\n",
      "\n",
      "[INFO] Zapytanie: site:businessinsider.com.pl prognoza bezrobocia 2023\n",
      "[INFO]  Pobieranie wynik√≥w start=1\n",
      "[INFO]  Pobieranie wynik√≥w start=11\n",
      "[INFO]  Pobieranie wynik√≥w start=21\n",
      "[INFO]  Pobieranie wynik√≥w start=31\n",
      "[INFO]  Pobieranie wynik√≥w start=41\n",
      "[INFO]  Pobieranie wynik√≥w start=51\n",
      "[INFO]  Pobieranie wynik√≥w start=61\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Dodatkowy skrypt:\n",
    "Dodaje zapytania o wska≈∫niki ekonomiczne do istniejƒÖcych plik√≥w CSV.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import csv\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "\n",
    "GOOGLE_API_ENDPOINT = \"https://www.googleapis.com/customsearch/v1\"\n",
    "GOOGLE_API_KEY_DEFAULT = \"AIzaSyCBNHQcyHhMSX4O0msII-dBHinGNqu5Q6o\"\n",
    "GOOGLE_CX_ID_DEFAULT = \"b4784a92b986540f9\"\n",
    "\n",
    "ALLOWED_SITES = [\n",
    "    \n",
    "    \"businessinsider.com.pl\",\n",
    "    \"pap.pl\",\n",
    "    \"tvn24.pl\",\n",
    "    \"obserwatorfinansowy.pl\",\n",
    "    \"pie.net.pl\"\n",
    "]\n",
    "YEARS = [2021, 2022, 2023]\n",
    "\n",
    "BLOCKED_SUBSTRINGS = [\"/premium\", \"/paywall\", \"token=\"]\n",
    "\n",
    "def _is_allowed_url(url: str) -> bool:\n",
    "    if not url:\n",
    "        return False\n",
    "    lower = url.lower()\n",
    "    for bad in BLOCKED_SUBSTRINGS:\n",
    "        if bad in lower:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def google_search(query: str, api_key: str, cx_id: str,\n",
    "                  start: int = 1, timeout: float = 20.0) -> dict:\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"cx\": cx_id,\n",
    "        \"q\": query,\n",
    "        \"start\": start,\n",
    "        \"num\": 10,\n",
    "        \"hl\": \"pl\",\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(GOOGLE_API_ENDPOINT, params=params, timeout=timeout)\n",
    "        resp.raise_for_status()\n",
    "        return resp.json()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if e.response.status_code == 400:\n",
    "            # B≈ÇƒÖd 400 oznacza zwykle przekroczenie limitu 100 wynik√≥w\n",
    "            print(f\"[WARN]  OsiƒÖgniƒôto limit wynik√≥w API (start={start}).\", file=sys.stderr)\n",
    "            return {}\n",
    "        if e.response.status_code == 403:\n",
    "            error_data = e.response.json()\n",
    "            if 'error' in error_data and 'message' in error_data['error']:\n",
    "                msg = error_data['error']['message']\n",
    "                print(f\"\\n[ERROR] ‚õî Google Custom Search API nie jest w≈ÇƒÖczone!\", file=sys.stderr)\n",
    "                print(f\"[ERROR] Wiadomo≈õƒá: {msg}\", file=sys.stderr)\n",
    "                if 'activationUrl' in str(error_data):\n",
    "                    print(f\"[ERROR] W≈ÇƒÖcz API tutaj: https://console.developers.google.com/apis/api/customsearch.googleapis.com/overview?project=59772975746\", file=sys.stderr)\n",
    "                print(f\"[ERROR] Po w≈ÇƒÖczeniu API poczekaj kilka minut i uruchom skrypt ponownie.\\n\", file=sys.stderr)\n",
    "        print(f\"[ERROR] Google Search ({query}) start={start}: {e}\", file=sys.stderr)\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Google Search ({query}) start={start}: {e}\", file=sys.stderr)\n",
    "        return {}\n",
    "\n",
    "def _extract_domain(url: str) -> str:\n",
    "    try:\n",
    "        return urlparse(url).netloc\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def _extract_date_from_metatags(pagemap: dict) -> str | None:\n",
    "    if not isinstance(pagemap, dict):\n",
    "        return None\n",
    "    metatags = pagemap.get(\"metatags\", [])\n",
    "    if not isinstance(metatags, list):\n",
    "        return None\n",
    "    date_keys = [\n",
    "        \"article:published_time\",\n",
    "        \"og:updated_time\",\n",
    "        \"publish-date\",\n",
    "        \"pubdate\",\n",
    "        \"datePublished\",\n",
    "        \"date\",\n",
    "    ]\n",
    "    for mt in metatags:\n",
    "        if not isinstance(mt, dict):\n",
    "            continue\n",
    "        for key in date_keys:\n",
    "            if key in mt and mt[key]:\n",
    "                return mt[key]\n",
    "    return None\n",
    "\n",
    "def build_queries_for_year(year: int) -> list[str]:\n",
    "    base_phrases = [\n",
    "        \"prognoza inflacji\",\n",
    "        \"prognoza PKB\",\n",
    "        \"prognoza wzrostu gospodarczego\",\n",
    "        \"prognoza bezrobocia\",\n",
    "        \"prognoza stopy referencyjnej NBP\",\n",
    "    ]\n",
    "    return [f\"{phrase} {year}\" for phrase in base_phrases]\n",
    "\n",
    "def search_reference_rate_only(\n",
    "    site: str,\n",
    "    year: int,\n",
    "    query_phrase: str,\n",
    "    api_key: str,\n",
    "    cx_id: str,\n",
    "    max_pages: int = 10,\n",
    "    delay: float = 1.0,\n",
    ") -> list[dict]:\n",
    "    \"\"\"Szuka zapyta≈Ñ ekonomicznych dla danego serwisu.\"\"\"\n",
    "    records = []\n",
    "    seen_urls = set()\n",
    "    \n",
    "    query = f\"site:{site} {query_phrase}\"\n",
    "    print(f\"\\n[INFO] Zapytanie: {query}\")\n",
    "    \n",
    "    # Google Custom Search API ma limit 100 wynik√≥w (10 stron √ó 10 wynik√≥w)\n",
    "    max_pages = min(max_pages, 10)\n",
    "    \n",
    "    for page_index in range(max_pages):\n",
    "        start = 1 + page_index * 10\n",
    "        print(f\"[INFO]  Pobieranie wynik√≥w start={start}\")\n",
    "        \n",
    "        data = google_search(query, api_key=api_key, cx_id=cx_id, start=start)\n",
    "        if not data:\n",
    "            print(\"[INFO]  Brak dalszych wynik√≥w lub osiƒÖgniƒôto limit API.\")\n",
    "            break\n",
    "        \n",
    "        items = data.get(\"items\", [])\n",
    "        if not items:\n",
    "            print(\"[INFO]  Brak dalszych wynik√≥w.\")\n",
    "            break\n",
    "        \n",
    "        for item in items:\n",
    "            url = item.get(\"link\")\n",
    "            if not url or not _is_allowed_url(url) or url in seen_urls:\n",
    "                continue\n",
    "            \n",
    "            seen_urls.add(url)\n",
    "            \n",
    "            rec = {\n",
    "                \"query\": query,\n",
    "                \"url\": url,\n",
    "                \"domain\": _extract_domain(url),\n",
    "                \"title_search\": item.get(\"title\", \"\") or \"\",\n",
    "                \"snippet_search\": item.get(\"snippet\", \"\") or \"\",\n",
    "                \"google_detected_date\": _extract_date_from_metatags(item.get(\"pagemap\", {})) or \"\",\n",
    "            }\n",
    "            records.append(rec)\n",
    "        \n",
    "        time.sleep(delay)\n",
    "    \n",
    "    print(f\"[INFO] Zebrano {len(records)} nowych rekord√≥w ({query_phrase})\")\n",
    "    return records\n",
    "\n",
    "def append_to_csv(records: list[dict], path: str) -> None:\n",
    "    \"\"\"Dopisuje nowe rekordy do istniejƒÖcego CSV (lub tworzy nowy).\"\"\"\n",
    "    if not records:\n",
    "        print(f\"[INFO] Brak nowych rekord√≥w do dodania ‚Üí {path}\")\n",
    "        return\n",
    "    \n",
    "    fieldnames = [\n",
    "        \"query\",\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "        'Accept-Language': 'pl-PL,pl;q=0.9,en;q=0.8',\n",
    "        'Referer': 'https://www.google.com/'\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=20)\n",
    "            response.raise_for_status()\n",
    "            response.encoding = response.apparent_encoding or 'utf-8'\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Usu≈Ñ niepotrzebne elementy\n",
    "            for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'iframe', 'aside', 'figure', 'img']):\n",
    "                tag.decompose()\n",
    "            \n",
    "            text_parts = []\n",
    "            \n",
    "            # STRATEGIA 1: Selektory specyficzne dla r√≥≈ºnych portali\n",
    "            selectors = [\n",
    "                # Bankier.pl\n",
    "                'article', 'div.articleBody', 'div.article-content',\n",
    "                # TVN24.pl\n",
    "                'article.article__body', 'div.article__body', 'div[itemprop=\"articleBody\"]',\n",
    "                # Business Insider\n",
    "                'div.post-content', 'article.article-body',\n",
    "                # PAP\n",
    "                'div.article-body', 'div.content-article',\n",
    "                # Obserwator Finansowy\n",
    "                'div.entry-content', 'article.post',\n",
    "                # PIE\n",
    "                'div.post-content', 'div.article-content',\n",
    "                # Uniwersalne\n",
    "                'main article', 'div.content-container', '.article-content'\n",
    "            ]\n",
    "            \n",
    "            for selector in selectors:\n",
    "                elements = soup.select(selector)\n",
    "                if elements:\n",
    "                    for elem in elements:\n",
    "                        # Pobierz wszystkie akapity, nag≈Ç√≥wki, listy\n",
    "                        paragraphs = elem.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'li', 'blockquote'])\n",
    "                        for p in paragraphs:\n",
    "                            text = p.get_text(strip=True)\n",
    "                            if len(text) > 20:  # Tylko sensowne fragmenty\n",
    "                                text_parts.append(text)\n",
    "                    \n",
    "                    if text_parts:\n",
    "                        break\n",
    "            \n",
    "            # STRATEGIA 2: Fallback - szukaj w main/article\n",
    "            if not text_parts:\n",
    "                main_content = soup.find('main') or soup.find('article')\n",
    "                if main_content:\n",
    "                    paragraphs = main_content.find_all(['p', 'h1', 'h2', 'h3', 'li'])\n",
    "                    text_parts = [p.get_text(strip=True) for p in paragraphs if len(p.get_text(strip=True)) > 20]\n",
    "            \n",
    "            # STRATEGIA 3: Ostateczny fallback - wszystkie paragrafy\n",
    "            if not text_parts:\n",
    "                paragraphs = soup.find_all(['p', 'h1', 'h2', 'h3'])\n",
    "                text_parts = [p.get_text(strip=True) for p in paragraphs if len(p.get_text(strip=True)) > 20]\n",
    "            \n",
    "            full_text = ' '.join(text_parts)\n",
    "            \n",
    "            if len(full_text) > 100:\n",
    "                print(f\"[INFO] ‚úì Scraped {len(full_text)} chars from {url.split('/')[2]}\")\n",
    "                return full_text  # BEZ LIMITU - zwracamy ca≈Çy tekst!\n",
    "            else:\n",
    "                print(f\"[WARN] Ma≈Ço tekstu ({len(full_text)} chars), retry {attempt+1}/{max_retries}\")\n",
    "            \n",
    "        except requests.exceptions.Timeout:\n",
    "            if attempt < max_retries - 1:\n",
    "                wait = 2 ** attempt\n",
    "                print(f\"[WARN] Timeout, retry za {wait}s\")\n",
    "                time.sleep(wait)\n",
    "            else:\n",
    "                print(f\"[ERROR] Timeout po {max_retries} pr√≥bach: {url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] B≈ÇƒÖd: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "def append_to_csv(records: list[dict], path: str) -> None:\n",
    "    \"\"\"ZMODYFIKOWANA WERSJA - dodaje pe≈Çny tekst artyku≈Çu\"\"\"\n",
    "    if not records:\n",
    "        print(f\"[INFO] Brak nowych rekord√≥w do dodania ‚Üí {path}\")\n",
    "        return\n",
    "    \n",
    "    fieldnames = [\n",
    "        \"query\",\n",
    "        \"url\",\n",
    "        \"domain\",\n",
    "        \"title_search\",\n",
    "        'Accept-Language': 'pl-PL,pl;q=0.9,en;q=0.8',\n",
    "        'Referer': 'https://www.google.com/'\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            response.encoding = 'utf-8'\n",
    "            \n",
    "            # Debug - zapisz pierwszy HTML\n",
    "            if DEBUG_MODE and attempt == 0:\n",
    "                save_debug_html(url, response.text)\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        print(f\"[INFO] Wszystkie URL-e ju≈º istniejƒÖ ‚Üí {path}\")\n",
    "            # Usu≈Ñ niepotrzebne elementy\n",
    "            for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'iframe', 'aside', 'figure']):\n",
    "                tag.decompose()\n",
    "    print(f\"[INFO] üï∑Ô∏è  Scrapujƒô pe≈Çne teksty dla {len(new_records)} artyku≈Ç√≥w...\")\n",
    "    for i, record in enumerate(new_records, 1):\n",
    "        url = record[\"url\"]\n",
    "        print(f\"[INFO] ({i}/{len(new_records)}) Scrapujƒô: {url}\")\n",
    "        \n",
    "        full_text = scrape_full_article_text(url)\n",
    "        record[\"full_article_text\"] = full_text\n",
    "        \n",
    "        time.sleep(1)  # Grzeczne op√≥≈∫nienie\n",
    "    \n",
    "    # Zapisz do CSV\n",
    "    with open(path, \"a\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        if not existing_urls:  # Plik nie istnia≈Ç\n",
    "            writer.writeheader()\n",
    "        writer.writerows(new_records)\n",
    "    \n",
    "    print(f\"[INFO] ‚úÖ Dodano {len(new_records)} artyku≈Ç√≥w z pe≈Çnymi tekstami ‚Üí {path}\")\n",
    "\n",
    "def main_reference_rate():\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\", GOOGLE_API_KEY_DEFAULT)\n",
    "    cx_id = os.getenv(\"GOOGLE_CX_ID\", GOOGLE_CX_ID_DEFAULT)\n",
    "    \n",
    "    print(\"[INFO] üîç Sprawdzanie po≈ÇƒÖczenia z Google Custom Search API...\")\n",
    "    test_result = google_search(\"test\", api_key=api_key, cx_id=c
    "                    paragraphs = main_content.find_all('p')\n",    "                    text_parts = [p.get_text(strip=True) for p in paragraphs if len(p.get_text(strip=True)) > 30]\n",    "                    if text_parts:\n",    "                        print(f\"[DEBUG] Znaleziono tekst przez main/article fallback\")\n",    "            \n",    "            # Strategia 3: Ostateczny fallback - wszystkie paragrafy\n",    "            if not text_parts:\n",    "                paragraphs = soup.find_all('p')\n",    "                text_parts = [p.get_text(strip=True) for p in paragraphs if len(p.get_text(strip=True)) > 30]\n",    "                if text_parts:\n",    "                    print(f\"[DEBUG] Znaleziono tekst przez ostateczny fallback\")\n",    "            \n",    "            full_text = ' '.join(text_parts)\n",    "            \n",    "            # OPCJONALNE: Czyszczenie tekstu\n",    "            def clean_text(text: str) -> str:\n",    "                \"\"\"Czy≈õci tekst z nadmiarowych spacji, znak√≥w specjalnych\"\"\"\n",    "                import re\n",    "                # Usu≈Ñ wielokrotne spacje\n",    "                text = re.sub(r'\\s+', ' ', text)\n",    "                # Usu≈Ñ znaki specjalne (opcjonalne)\n",    "                text = re.sub(r'[^\\w\\s\\.,!?;:\\-()]', '', text)\n",    "                return text.strip()\n",    "            \n",    "            # W funkcji scrape_full_article_text() przed return:\n",    "            full_text = clean_text(' '.join(text_parts))\n",    "            \n",    "            if len(full_text) > 0:\n",    "                print(f\"[INFO] Znaleziono {len(full_text)} znak√≥w tekstu\")\n",    "                return full_text[:8000]  # Przytnij do 8000 znak√≥w\n",    "            else:\n",    "                print(f\"[WARN] Nie znaleziono tekstu, pr√≥ba {attempt+1}/{max_retries}\")\n",    "            \n",    "        except requests.exceptions.Timeout:\n",    "            if attempt < max_retries - 1:\n",    "                wait = 2 ** attempt\n",    "                print(f\"[WARN] Timeout, retry za {wait}s\")\n",    "                time.sleep(wait)\n",    "            else:\n",    "                print(f\"[ERROR] Timeout po {max_retries} pr√≥bach\")\n",    "        except Exception as e:\n",    "            print(f\"[ERROR] B≈ÇƒÖd scrapowania: {e}\")\n",    "            if attempt < max_retries - 1:\n",    "                time.sleep(2 ** attempt)\n",    "    \n",    "    return \"\"\n",    "\n",    "# W g≈Ç√≥wnej pƒôtli zmie≈Ñ wywo≈Çanie funkcji scrapowania:\n",    "# BY≈ÅO:\n",    "# article_text = scrape_article_text(url)\n",    "\n",    "# JEST:\n",    "article_text = scrape_article_text_tvn24(url)\n"   ]  },  {   "cell_type": "code",   "execution_count": null,   "metadata": {},   "outputs": [],   "source": []  } ], "metadata": {  "kernelspec": {   "display_name": "Python 3",   "language": "python",   "name": "python3"  },  "language_info": {   "codemirror_mode": {    "name": "ipython",    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
